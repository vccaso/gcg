# Go Code Generator (GCG) ğŸ› ï¸

An extensible AI Agent Orchestrator for generating Go CRUD code, Angular apps, GitHub automations, images, audio, video, subtitles, and more â€” using local and cloud-based LLMs.

---

## ğŸ§° Built With
- ğŸ§  Python 3
- ğŸ–¥ï¸ Streamlit UI
- ğŸ“œ YAML-based workflow engine
- ğŸ§© Modular agent/model system
- ğŸŒ OpenAI, Ollama, DeepSeek, Coqui TTS
- ğŸ³ Optional Docker support

---

## ğŸ“† Requirements

- Python 3.8+
- Pip + virtualenv
- Docker (optional)
- OpenAI or HuggingFace or Ollama access

---

## ğŸ”§ Setup Instructions

```bash
git clone https://github.com/your-username/gcg.git
cd gcg
python3 -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install --no-cache-dir -r requirements.txt
```

---

## ğŸ§  Supported LLM Models

| Model | Use | Tags |
|:------|:----|:-----|
| `ModelOllama` | Offline dev & chat | [Local], [LLM] |
| `ModelDeepSeekCoder67` | Advanced coding (Go, Python) | [Local], [Code] |
| `ModelGpt4Turbo` | Structured workflows | [OpenAI] |
| `ModelGpt35Turbo` | Quick drafts | [OpenAI] |
| `ModelDalle3` | Text-to-image | [OpenAI], [Image] |
| `ModelTTS1` | Text-to-speech | [OpenAI], [Audio] |
| `ModelWhisper` | Speech-to-text | [OpenAI], [Audio] |
| `ModelTTSCoqui` | Offline text-to-speech (Coqui TTS) | [Local], [Audio] |
| `ImageModelStableDiffusion` | Local/remote image generation | [Local], [Image]

âœ… Browse and filter models via Streamlit UI

---

## ğŸ¤– Supported AI Agents

### ğŸ§  Core
- `ChatAgent` â€” General chat / idea generation
- `GoCRUDAgent` â€” Full Go CRUD generation
- `AngularAppAgent` â€” Angular frontend builder

### ğŸ¨ Image & Audio
- `Dalle3Agent` â€” Generate image via DALLÂ·E
- `ImageAgent` â€” Unified image agent w/ pluggable models
- `SegmentedImageAgent` â€” Image per scene/section
- `AudioAgent` â€” TTS/STT engine
- `SegmentedAudioAgent` â€” Per-section speech audio
- `SegmentedSubtitleGeneratorAgent` â€” Builds subtitles from TTS
- `SegmentedVideoAssemblerAgent` â€” Final video creator from image + audio

### âœ… Validators
- `ScriptStructureValidatorAgent` â€” Checks script sections
- `ScriptFeedbackValidatorAgent` â€” Scores script and suggests improved prompt

### ğŸ› ï¸ Utility
- `SaveToFileAgent`, `RequirementsExtractorAgent`
- `GitHub*` agents (branch, commit, PR)
- `RAG*` agents for retrieval pipelines

âœ… Filter & explore agents in Streamlit UI

---

## ğŸ§ª Sample Workflow

```yaml
vars:
  topic: "How to prioritize tasks effectively"
  name: "productivity"

steps:
  - name: generate_script
    type: ai
    agent: ChatAgent
    model: ModelGpt35Turbo
    input:
      question: ${topic}

  - name: generate_audio
    type: ai-audio
    agent: AudioAgent
    model: ModelTTS1
    input:
      mode: tts
      text: "{{ generate_script.result }}"
      output_path: workspace/audio/${name}.wav
      factor: 1.4

  - name: generate_thumbnail
    type: ai-image
    agent: ImageAgent
    model: ImageModelStableDiffusion
    input:
      prompt: "Thumbnail for: ${topic}"
      output_path: workspace/images/${name}.png
```

---

## ğŸ¬ Segmented Video Assembly

Compose narrated videos using multiple agents:

1. `ChatAgent` + YouTube template (text/image_prompt)
2. `SegmentedAudioAgent`
3. `SegmentedImageAgent`
4. `SegmentedSubtitleGeneratorAgent`
5. `SegmentedVideoAssemblerAgent`

---

## ğŸŒ OpenAI Configuration

```bash
export OPENAI_API_KEY=your-key
```

---

## ğŸ’» Local Model Support

### ğŸ¦™ Ollama (for local LLMs)
```bash
ollama pull llama3
ollama run llama3
```

### ğŸ¸ Coqui TTS (local TTS)
```bash
pip install TTS
tts --model_name tts_models/en/ljspeech/tacotron2-DDC --download
```

### Sample Python Usage
```python
from TTS.api import TTS
tts = TTS(model_name="tts_models/en/ljspeech/tacotron2-DDC")
tts.tts_to_file("Hello world", file_path="output.wav")
```

---

## ğŸ“‚ Project Layout

| Folder | Purpose |
|--------|---------|
| `workflows/` | YAML workflow definitions |
| `agents/` | Task-specific agents |
| `models/` | Audio, image, LLM models |
| `schemas/` | JSON validation schemas |
| `utils/` | YAML, JSON, printer helpers |
| `api/` | FastAPI server |
| `ui.py` | Streamlit UI |
| `run_cli.py` | CLI runner |

---

## ğŸ³ Docker Support

```bash
docker build -t gcg-agent .
docker run -p 8000:8000 -e OPENAI_API_KEY=your-key gcg-agent
```

Or for UI:

```bash
docker run -p 8501:8501 -e OPENAI_API_KEY=your-key gcg-agent streamlit run ui.py
```

---

## ğŸ§ª Workflow DSL Support

| Pattern | Example | From |
|---------|---------|------|
| `${var}` | `${topic}` | `vars:` |
| `step.result` | `step1.result` | Previous step |
| `{{ var }}` | `{{ filename }}` | Jinja |
| `{{ step.result }}` | `{{ generate_script.result }}` | Jinja |

---

## âœ… Validation

```bash
python3 run_cli.py --validate
```

Or via Streamlit > Validation tab

---

## ğŸŒ API Server (FastAPI)

```bash
export GCG_API_KEY=secret-key
python3 api/main.py
```

POST `/run-workflow`:
```json
{
  "workflow_file": "examples/youtube/wf_segmented_01.yaml"
}
```

Header:
```http
x-api-key: secret-key
```

---

## ğŸ“œ License

MIT â€” Fork, contribute, and scale it your way!

---

## ğŸ’¡ Final Words

âœ… Design agent workflows  
âœ… Run offline or cloud LLMs  
âœ… Generate code, media, and content pipelines  
âœ… Modular, extensible, and production-ready
