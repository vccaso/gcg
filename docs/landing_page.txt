ğŸ§  OrishAI â€” Orchestrate Intelligent Agents with Ease
OrishAI is a powerful, modular framework for building and running AI workflows using local or cloud-based large language models. Designed for developers, researchers, and automation enthusiasts, OrishAI lets you create intelligent agents that collaborate through YAML-defined workflows â€” all with zero vendor lock-in.

ğŸš€ What You Can Do with OrishAI
Automate coding tasks with LLM-powered agents that write, test, and document code
Run local or cloud models â€” switch between OpenAI and local Ollama models with ease
Publish workflows to interact with GitHub, Facebook, APIs, and more
Design custom assistants for content generation, summarization, or customer support
Save and audit outputs automatically in plain text or structured logs
ğŸ’¡ Why OrishAI?
ğŸ§© Modular agent architecture â€” plug in your own logic, models, and tools
ğŸ“ Workflow as YAML â€” describe AI task pipelines in plain English
ğŸ’» Run via CLI or UI â€” command-line friendly with an elegant Streamlit front end
ğŸ”„ Local-first + Cloud-ready â€” use LLaMA3 or Mistral locally, or tap into OpenAI's GPTs
ğŸ“‚ Logs and versioning â€” track what was asked, answered, and executed
ğŸ”Œ Use Cases
LLM-powered developer tools
Custom ChatGPT-style agents
Social media automation
Knowledge-based assistants
Enterprise AI pipelines
âš¡ Get Started in Minutes
pip install -r requirements.txt
streamlit run run_ui.py
ğŸ” Fully Yours
No cloud lock-in. No platform rules. With OrishAI, you own the models, the logic, and the data.