📌 Project Description
LLM-Orchestrated AI Agent Framework

This project is a modular framework for building and orchestrating AI agents that interact with Large Language Models (LLMs) — both cloud-hosted (e.g., OpenAI) and locally hosted (via Ollama). It enables developers to define AI workflows using YAML files, run them via command-line or Streamlit-based UI, and plug in custom agents to automate tasks like code generation, chatting, summarization, or integrations with external services such as GitHub or Facebook.

Agents follow a consistent interface and can dynamically generate content, process user input, or trigger downstream actions. Workflows are declarative, making the system extensible and low-maintenance.

✨ Key Features
🧠 LLM Abstraction – Easily switch between OpenAI's GPT models and local Ollama models
🛠 Extensible Agent Interface – Add your own agent logic using a clean base class
📜 YAML Workflow Support – Define multi-step workflows with inputs, outputs, and chaining
🖥️ Streamlit UI – Friendly UI for selecting and running workflows
💻 CLI Support – Run workflows from the terminal with version flags
📝 Optional Logging – Save agent responses to file for later reference or auditing
🔌 Plugin-Ready Architecture – Easily add agents for GitHub, Facebook, Docs, etc.
📚 Example Use Cases
AI-powered code generation pipelines
Chat agents that log interactions to disk
Automation agents for social media tasks
Data extraction, transformation, and summarization agents
Fine-tuned workflow assistants using custom prompts
